Programs to support:
- Modular Compatibility (Midori AI Docker Subsystem)

- LLM Hosts:
    - Ollama (Docker)
    - Oobabooga (Docker)
    - LocalAI (Docker)

- Photo AI Hosts:
    - InvokeAI (Commandline)
    - Automatic1111 (Docker? / Commandline?) | (Apply fix for extension install crashing due to file system permissions)

- LLM FineTuning Hosts:
    - Axolotl (Commandline) | User will have to use command line to self install

- Other Tools:
    - AnythingLLM (Docker)
    - BigAGI (Docker)
    - ChromaDB for LLM memory applications

Features
- Add file already exists check. (prompt user prior to overwriting. if overwriting is denied, prompt user for the model "name" to set and then set yaml filename to model "name")
- User Control / AI Control

UI Frameworks
- React
- No UI
Notes:
Id love to add a chat room type of webui, but I am not sure how id want to do that...

AI Frameworks
- Google Gem EX (OpenAPI)
- Carly V3 (Autogen / OpenAI)
- OpenAI (Autogen / OpenAI)

AI QNA

**Questions about the subsystem**

1. What is the purpose of the Midori AI Subsystem?
2. How does the Midori AI Subsystem simplify AI deployment?
3. What are the benefits of using the Midori AI Subsystem?
4. What are the limitations of the Midori AI Subsystem?
5. What are the recommended prerequisites for using the Midori AI Subsystem?
6. How do I install the Midori AI Subsystem Manager?
7. Where can I find more information about the Midori AI Subsystem?
8. What is the difference between the Midori AI Subsystem and other AI frameworks?
9. How does the Midori AI Subsystem handle security?
10. What are the plans for future development of the Midori AI Subsystem?

**Questions about the supported backends**

1. What LLM Hosts are supported by the Midori AI Subsystem?
2. What Photo AI Hosts are supported by the Midori AI Subsystem?
3. What LLM FineTuning Hosts are supported by the Midori AI Subsystem?
4. What Other Tools are supported by the Midori AI Subsystem?
5. How do I install a specific backend on the Midori AI Subsystem?